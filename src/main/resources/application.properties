# Application Mode Configuration
app.mode=github
app.repository=${GITHUB_REPOSITORY:octocat/Hello-World}
app.pullRequestNumber=${PR_NUMBER:0}
# Git Configuration (for local mode)
app.fromCommit=HEAD~1
app.toCommit=HEAD
# LLM Configuration - LangChain4j
# Production defaults to OpenAI
langchain4j.open-ai.chat-model.api-key=${OPENAI_API_KEY}
langchain4j.open-ai.chat-model.model-name=${MODEL:gpt-4o}
langchain4j.open-ai.chat-model.timeout=45s
langchain4j.open-ai.chat-model.temperature=0.1
langchain4j.open-ai.chat-model.max-retries=2

# Ollama configuration (for local development)
# langchain4j.ollama.chat-model.base-url=${OLLAMA_HOST:http://localhost:1234}
# langchain4j.ollama.chat-model.model-name=${MODEL:deepseek-coder-6.7b-instruct}
# langchain4j.ollama.chat-model.timeout=45s
# langchain4j.ollama.chat-model.temperature=0.1
# Diff Configuration
app.contextLines=5
app.maxLinesPerChunk=1500
# Project Configuration
app.defaultBranch=main
app.javaVersion=17
app.buildSystem=maven
# GitHub Configuration (Environment Variables)
# GITHUB_TOKEN is read directly from environment variables
# Logging
logging.level.com.ghiloufi.aicode=INFO
logging.level.root=WARN