app.mode=local
app.repository=${GITHUB_REPOSITORY:C:\\Users\\PC\\IdeaProjects\\java-code-review-poc}
app.pullRequestNumber=${PR_NUMBER:0}

# LLM Configuration - LangChain4j

# OpenAI configuration for LM Studio (OpenAI-compatible)
langchain4j.open-ai.chat-model.api-key=${OPENAI_API_KEY:dummy}
langchain4j.open-ai.chat-model.base-url=${OLLAMA_HOST:http://localhost:1234/v1}
langchain4j.open-ai.chat-model.model-name=${MODEL:deepseek-coder-6.7b-instruct}
langchain4j.open-ai.chat-model.timeout=45s
langchain4j.open-ai.chat-model.temperature=0.1
langchain4j.open-ai.chat-model.max-retries=2

# Ollama configuration (disabled for LM Studio)
# langchain4j.ollama.chat-model.base-url=${OLLAMA_HOST:http://localhost:11434}
# langchain4j.ollama.chat-model.model-name=${MODEL:deepseek-coder}
# langchain4j.ollama.chat-model.timeout=45s
# langchain4j.ollama.chat-model.temperature=0.1
# langchain4j.ollama.chat-model.max-retries=2

# Diff Configuration

app.diff.contextLines=5
app.diff.maxLinesPerChunk=1500
# Project Configuration
app.project.defaultBranch=main
app.project.javaVersion=17
app.project.buildSystem=maven
# GitHub Configuration (Environment Variables)
# GITHUB_TOKEN is read directly from environment variables
# Logging
logging.level.com.ghiloufi.aicode=INFO
logging.level.root=WARN